# 作業ログ

- github repo 作った
- what i know メモを作った
- 念の為確認したが ChatGPT は Stable Diffusion も StableLM もない時代の知識らしい
- 各種必要な環境を調べる
  - StableLM Instruct の方の Huggingface のページでも読む
- 軽くサンプルコードや requirements をみて、派生的な知識を得る
- huggingface のファイル群をざっと見る
- 最終的には GKE で使うときだけ Web UI を立ち上げるみたいにしたいけど、一旦普通の Compute Engine インスタンスを立てる
  - どのくらいだろとりあえず T4 / n1-highmem-8 / Ubuntu 22.04 / 100 GB / スポットくらいな感じで。こういうとき Ubuntu じゃないほうが良いんだろうか
    - 0.36 USD/hour
      - 消し忘れたら月 30000 円くらい飛ぶ感じで
    - 慣れてるって理由だけで Ubuntu だけど。どのディストリビューションに何が入ってるか全く知らない
  - スポットだから別のゾーンじゃないと借りられないかなとかも検討してたけど、すんなり instance allocation された
- Compute Engine の instance のセットアップスクリプトは[scripts/setup\_instance](../scripts/setup_instance)にまとめていく
  - nvidia driver 535
  - cuda 11.8
  - python 3.10
- 環境セットアップは [scripts/setup\_env.sh](../scripts/setup_env.sh)
- instruct の方で遊んでみるが、データセットを見て、質問を答えることがメインな感じがした。 base の方でちょっと遊んでみるかという感じ
  - [stablelm\_sandbox/try\_base\_model.py](../stablelm_sandbox/try_base_model.py)
  - [stablelm\_sandbox/try\_instruct\_model.py](../stablelm_sandbox/try_instruct_model.py)
- [dialog.py](../stablelm_sandbox/dialog.py) というのを作ってちょっと遊んでみた。コンテキストの抽出とか、コンテキストの渡し方とかいろんな工夫が必要そう。
- まず、 2048 トークンにどのくらいの情報を載せられるのかを知る必要があるので、いくつかの長さの違う文章を入れてみて。どの程度のものなのか感覚値を掴む。
  - 長すぎる場合、適当にトークンを等間隔で分割して、それぞれ文字数指定で要約させて。短文を組み合わせて、大意を推移させるなどの手法を試してみる
  - [research\_token\_length.py](../stablelm_sandbox/research_token_length.py) でトークンごとの情報量を調べる。
  - 簡単なフォーマットを作ってみる
    - とりあえず [prompt\_template](../prompt_template) ディレクトリに入れていこう
      - あとで jinja2 を使う予定なので拡張子は j2 にしとく
    - [prompt\_template/000.j2](../prompt_template/000.j2) を作って試してみた
      - 全然ダメ、フォーマットに従うっていう気が全然ない
      - このモデルを使うとしたら、文脈上自然に現れるようなフォーマットを使うしかない。ファインチューニングするなら別。
- とりあえず、長い文を繰り返すと T4 は限界っぽいので A100 40GB 試してみよう
  - だんだんとコストが上がってきてぴえん味が深い🥺
- 最初のトライアルがあまりにもぴえんだったので、早々に切り上げてトレーニングを視野に入れた調査をした方がいい気もしてきたがどうすっべか。
- この行を書いている時点で深夜なので今日はもう寝るけど明日は以下をやりたい
  - まず T4 じゃダメなんで A100 40GB をインスタンスのセットアップからやる
  - AIのべりすとのプロンプトのテンプレートを発見したので AI のべりすとと結果の比較しながら、フォーマットに特化した train が重要か重要でないか感覚を得る
- T4 インスタンスを削除して A100 40GB をセットアップする

