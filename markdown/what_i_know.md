# わかったこと/決めたこと

- 基本
  - [このモデルを使う](https://huggingface.co/stabilityai/japanese-stablelm-base-alpha-7b)
- とりあえず分かる範囲で必要なライブラリとか
  - torch
  - transformers
  - einops
  - sentencepiece
  - cuda
- バージョンとか。一旦以下のような環境を作ってみる
  - nvidia driver 535
  - cuda 11.8
  - python 3.10
  - torch 2.0.1
    - python 3.8 ~
    - cuda 11.7 or 11.8
  - transformers 4.31.0
    - torch 1.9 ~ ただし 1.12.0 はダメ
    - python 3.8 or 3.9 or 3.10
  - einops 0.6.1
    - python 3.7 ~
  - sentenncepiece 0.1.99
- モデルの詳細
  - 最長 1024 トークン（与える文字列 + 追加される文字列）
- ML の基礎知識的なこと
  - AutoModelForCausalLM ってどんなモデル
    - 文章の続きを書いたり、会話に回答したりする出力ヘッドを持つモデル。 CLM とか略すらしい
  - NIDIA/Megatron-LM という transformer ベースのモデルの学習を大規模高速化するための手法を使っている。 GPT-NeoX というのがその環境とかツールキットの名前
    - GPU を増やして、線形に FLOPS を増やすことが目的。完全に大規模むけ
    - StableLM は GPT-NeoX で学習され huggingface 用に変換されて公開されている
- ファイル群
  - fp16 用とそれ以外の weight がある
  - index.json でクラスの重みとして読む
  - クラスは transformer の PreTrainedModel を継承した JapaneseStableLMAlphaForCausalLM。 AutoModelForCausalMl は config.json を見てこれを使う
  - かなりシンプル
- 実行環境としては 100 GB のストレージがあればいい。モデルをダウンロードする分で数十GB って感じ

# わかってないこと/決まってないこと

- 架空や実在の人物の mimic と会話することってできるんですか？
  - 故人とか
  - 歴史上の人物とか
  - アイドルとか
  - 小説の中の人物とか
- いい感じの Web UI とかってすでに開発されてる？最悪 X 経由でアクセス可能な GUI でも良い。
- ネット小説とか学習させたら、その中のキャラになってくれるの？
- 追加学習の手法は？
  - few shot, one shot は?
  - dream booth 的な手法はどう？
  - every dream 的な手法はどう？
  - lora は？
- モデルシェアサイトはすでにある？
- chichipui 的な小説サイトは可能性あるの？人格を公開して遊ぶ感じ？ディストピア？
- decoder-only model って何？
  - encoder は他のモデルの使ってますってことですかね
- [requirements.txt](https://huggingface.co/stabilityai/japanese-stablelm-instruct-alpha-7b/blob/main/requirements.txt) には `sentencepiece` `einops` しか書いてないけど、 transformers とかはいらないのか？
  - 自分は huggingface リポジトリのことわかってないかもしれない
- 先行する英語圏の CausalLM に関する知見を収集したい。
- 1024 ってどのくらいの情報量なの？
- モデルが私をどう知るのが良いのか
  - モデル自身は自分を知らないパターンがいいのか。毎回質問に付随して、二人の文脈を与えるパターン。
  - モデル自身が自分を知っているパターンがいいのか。自分専用にモデルに知識や傾向、回答のフォーマットなどを与える。 (instruct model を自分専用に作るようなもの)
  - 一週間前の知識とかはどうする？全てのやり取りの履歴を prompt に埋め込むことができないし、日本語とその知識に自分とのやり取りを混ぜるのも違うと思う。
    - 何かブレークスルーがありそう。この辺は何かそういう研究してる人がいそうなので調べる
- 差し当たってモデルと会話するために、テンプレートを作る必要がある。
  - これも先行事例が英語圏に大量にありそう
  - instruct モデルだと ### 支持\nXXXXX\n### 回答\nYYYYYY のようなテンプレートを持っていて、それを前提に学習してるので無駄がない。
  - 例えば、誰かと会話してる雰囲気にするには以下の情報を 1024 トークンに埋め込みたい
    - 二人の間の順序が関係ない共有知識(普遍的なものなのでモデルに学習させてもいいかも)
    - 二人の間の時系列情報
    - 直近数回のやり取りの詳細
    - 回答者の人格の設定
    - 書き加えて欲しい情報のフォーマットを伝える
    - 新しい発言
    - 新しい発言への回答（AI が生成する部分。パース可能でなければならない）
    - 忘れるべき情報の選択（AI が生成する部分。パース可能でなければならない）
    - 追加すべき情報（AI が生成する部分。パース可能でなければならない）
  - 複数の情報を AI から得るには解答のフォーマットもこちら側から伝えなければならない
    - パースエラーになったら、パース成功するまで繰り返せばいいし、一人専用の AI だとするとバッチの数を増やしていいものを使えばいい。多数決的な枠組みも使えるかもしれない。

